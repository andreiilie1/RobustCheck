<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Usage &#8212; RobustCheck  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=12dfc556" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Robustness metrics" href="metrics.html" />
    <link rel="prev" title="RobustCheck documentation" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Link to this heading">¶</a></h1>
<section id="installation">
<span id="id1"></span><h2>Installation<a class="headerlink" href="#installation" title="Link to this heading">¶</a></h2>
<p>To use RobustCheck, first install it using pip:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(.venv)</span> <span class="gp">$ </span>pip<span class="w"> </span>install<span class="w"> </span>robustcheck
</pre></div>
</div>
</section>
<section id="data-and-model-preparation">
<h2>Data and model preparation<a class="headerlink" href="#data-and-model-preparation" title="Link to this heading">¶</a></h2>
<p>Ensure your model exposes a <code class="docutils literal notranslate"><span class="pre">.predict(image_batch)</span></code> function which can take as
input an <code class="docutils literal notranslate"><span class="pre">np.array</span></code> batch of images and produces as output an array of arrays
representing the probability distributions for each image in the batch to be
classified as any of the existing classes.</p>
<p>You will have to provide a sample of images (<code class="docutils literal notranslate"><span class="pre">x_test</span></code>) with their correct labels
(<code class="docutils literal notranslate"><span class="pre">test_labels</span></code>). These have to be of <code class="docutils literal notranslate"><span class="pre">np.array</span></code> type.</p>
</section>
<section id="set-up-a-robustnesscheck-object">
<h2>Set up a RobustnessCheck object<a class="headerlink" href="#set-up-a-robustnesscheck-object" title="Link to this heading">¶</a></h2>
<p>Create a <code class="docutils literal notranslate"><span class="pre">RobustnessCheck</span></code> object with your model, test data, and attack parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">robustcheck</span>

<span class="n">rc</span> <span class="o">=</span> <span class="n">robustcheck</span><span class="o">.</span><span class="n">RobustnessCheck</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">x_test</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">test_labels</span><span class="p">,</span>
    <span class="n">attack</span><span class="o">=</span><span class="n">AttackType</span><span class="o">.</span><span class="n">EVOBA</span><span class="p">,</span>
    <span class="n">attack_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;generation_size&quot;</span><span class="p">:</span> <span class="mi">160</span><span class="p">,</span>
        <span class="s2">&quot;one_step_perturbation_pixel_count&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;pixel_space_int_flag&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;pixel_space_min&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;pixel_space_max&quot;</span><span class="p">:</span> <span class="mi">255</span><span class="p">,</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;steps&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="run-the-robustness-check">
<h2>Run the robustness check<a class="headerlink" href="#run-the-robustness-check" title="Link to this heading">¶</a></h2>
<p>Execute the robustness check:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">robustness_metrics</span> <span class="o">=</span> <span class="n">rc</span><span class="o">.</span><span class="n">run_robustness_check</span><span class="p">()</span>
</pre></div>
</div>
<p>This is where you actually run the robustness checks by triggering an adversarial attack
against each image that is correctly classified by model in the provided <code class="docutils literal notranslate"><span class="pre">x_test</span></code> sample.</p>
<p><code class="docutils literal notranslate"><span class="pre">robustness_metrics</span></code> is a dictionary containing a mapping between robustness metrics such as
<code class="docutils literal notranslate"><span class="pre">count_succ</span></code> (how many samples were successfully perturbed) and their values. It also contains
raw results, for example through the mapping between <code class="docutils literal notranslate"><span class="pre">l0_dists_succ</span></code> and a list of all L0 norms
of all successful adversarial perturbations.</p>
</section>
<section id="review-the-robustness-metrics">
<span id="review-robustness-metrics"></span><h2>Review the robustness metrics<a class="headerlink" href="#review-the-robustness-metrics" title="Link to this heading">¶</a></h2>
<p>While <code class="docutils literal notranslate"><span class="pre">robustness_metrics</span></code> contains all relevant metrics of the robustness check, we provide
friendlier ways to review these.</p>
<p>There are various ways to interact with the robustness metrics that <code class="docutils literal notranslate"><span class="pre">run_robustness_check()</span></code>
produce. You can print them in a human-readable form, generate and store artifacts containing
metrics and various plots on the disk, or generate MLFlow logs containing metrics and artifacts.</p>
<p><strong>Note</strong>: Check the <a class="reference internal" href="metrics.html#robustness-metrics"><span class="std std-ref">robustness metrics page</span></a> to understand which metrics we compute
and how to interpret them.</p>
<section id="printing-robustness-metrics-in-a-human-readable-form">
<h3>Printing robustness metrics in a human-readable form<a class="headerlink" href="#printing-robustness-metrics-in-a-human-readable-form" title="Link to this heading">¶</a></h3>
<p>You can print the robustness metrics to the standard output by running:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rc</span><span class="o">.</span><span class="n">print_robustness_stats</span><span class="p">()</span>
</pre></div>
</div>
<p>This will produce an output containing all relevant metrics. For example, the output can look like:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">EvoBA STATS (L0 attack)</span>
<span class="go">___________________</span>
<span class="go">Perturbed successfully 13/13 images</span>
<span class="go">Average query count: 264.0769230769231</span>
<span class="go">Average l0 distance: 26.076923076923077</span>
<span class="go">Average l2 distance per pixel: 0.0006845784778314443</span>

<span class="go">Median query count: 211.0</span>
<span class="go">Median l0 dist: 21.0</span>

<span class="go">Max query count: 751</span>
<span class="go">Max l0 dist: 75</span>
<span class="go">___________________</span>
</pre></div>
</div>
</section>
<section id="generating-and-storing-artifacts-on-the-disk">
<h3>Generating and storing artifacts on the disk<a class="headerlink" href="#generating-and-storing-artifacts-on-the-disk" title="Link to this heading">¶</a></h3>
<p>Another option is saving the robustness metrics and other relevant artifacts such as image-level
histograms of the relevant metrics by running the snippet below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">robustcheck.utils</span> <span class="kn">import</span> <span class="n">save_robustness_stats_artifacts</span>
<span class="n">save_robustness_stats_artifacts</span><span class="p">(</span><span class="n">rc</span><span class="p">,</span> <span class="n">path_to_output</span><span class="p">)</span>
</pre></div>
</div>
<p>This will produce the following artifacts at the path <code class="docutils literal notranslate"><span class="pre">path_to_output</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">l0_dists_histogram.png</span></code> and <code class="docutils literal notranslate"><span class="pre">l2_dists_histogram.png</span></code> - histograms of the successful adversarial perturbation norms</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">queries_histogram.png</span></code> - a histogram of the query counts needed for successful adversarial perturbations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">robustness_stats.json</span></code> - a JSON file containing both the relevant robustness metrics and the raw results
(non-aggregated lists of query counts and perturbation norms).</p></li>
</ul>
</section>
<section id="generating-mlflow-logs">
<h3>Generating MLFlow logs<a class="headerlink" href="#generating-mlflow-logs" title="Link to this heading">¶</a></h3>
<p>Finally, you can use MLFlow to generate logs for the robustness check. These will contain all metrics and artifacts
of the methods above, but will additionally use MLFlow’s UI to visualise both the perturbed and unperturbed images.
This should provide you a qualitative understanding of how successful perturbations look like and assess how perceptible
these are. You can generate MLFlow logs by running:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">robustcheck.utils</span> <span class="kn">import</span> <span class="n">save_robustness_stats_artifacts</span>
<span class="n">generate_mlflow_logs</span><span class="p">(</span><span class="n">rc</span><span class="p">,</span> <span class="n">run_name</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">,</span> <span class="n">tracking_uri</span><span class="p">)</span>
</pre></div>
</div>
<p>This will generate MLFlow compatible artifacts under the run <code class="docutils literal notranslate"><span class="pre">run_name</span></code> and under the experiment <code class="docutils literal notranslate"><span class="pre">experiment_name</span></code>
stored at the <code class="docutils literal notranslate"><span class="pre">tracking_uri</span></code> location, which can either be a local path or a dedicated MLFlow server. Read more
about how to use MLFlow <a class="reference external" href="https://mlflow.org/docs/latest/getting-started/index.html">here</a>.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">RobustCheck</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Main content:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-and-model-preparation">Data and model preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#set-up-a-robustnesscheck-object">Set up a RobustnessCheck object</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-the-robustness-check">Run the robustness check</a></li>
<li class="toctree-l2"><a class="reference internal" href="#review-the-robustness-metrics">Review the robustness metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Robustness metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="RobustnessCheck.html">RobustnessCheck API</a></li>
<li class="toctree-l1"><a class="reference internal" href="dump_metrics.html">Dumping robustness check results</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Adversarial attacks documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="EvoStrategyUniformUntargeted.html">EvoStrategyUniformUntargeted</a></li>
<li class="toctree-l1"><a class="reference internal" href="EpsilonGreedyUntargeted.html">EpsilonGreedyUntargeted</a></li>
<li class="toctree-l1"><a class="reference internal" href="UntargetedAttack.html">UntargetedAttack</a></li>
<li class="toctree-l1"><a class="reference internal" href="EvoStrategy.html">EvoStrategy</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">RobustCheck documentation</a></li>
      <li>Next: <a href="metrics.html" title="next chapter">Robustness metrics</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023, Andrei Ilie.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/usage.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>